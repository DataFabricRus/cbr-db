1.  RAW DATA IMPORT
===================

Expertise: sql, python, linux

Download
--------
No complaints

Unpack
------
No complaints


Make CSV
--------
Slow
Hidden truncation of data

Import CSV
----------
Pros: fast import using mysqlimport
Troubles: import form 102 codes as int  

Import bank | plan
------------------
cbr_db.majorbanks
some import tables not needed (only benchmark tables)

Other
-----
tools to update database procedurtes without overwriting data
full dump of all database 
setup script (2012 2015)  

2. RAW DATA TRANSFORMATION AND MIGRATION
========================================

Make dataset
------------
Trouble:
+ slow
+ test integrity
+ kick out dates 
+ show what regn are present by date


Migrate dataset
---------------
No complaints

3. DATA ANALYSIS
================

Make balance +  test



Issues by FORM
==============

***


-----------------------------------------------------------------------------------

Blocks of work
==============

f101 + f102 + side tables 
different directory for database data - config file
truncation cli + sql queries 

f102 import from private file

pandas abstraction
www frontend (commands + 'output' directory)

as listed in 'critical'

csv + xlsx style results 

replicate "fitch"-style tables and aggregates

Listed in *Github Issues*
=========================
write to existing file openpyxl

explicit regn and date limit when truncating raw database (hardcoded in database)
    bankform.py make dataset <FORM> --regn=<regn_list> --regn-file<file> --dates 2012 2015
    bankform.py make dataset <FORM> --regn=956,1000 --regn-file regn.txt --dates 2015
	must look for regn.txt in current directory or DIRLIST['global']['tables']
	now regn list is hard-coded in views f101_long, f101_*.
	
import form 102

directory structure: 
	same in public/private
	101:
	  csv
	  rar
	  dbf
	  txt
	different path to local data folder (non-standard)
	no 'www' in folder or database names

pandas dataframe - more explicit data aggregation algorithm 


Critical
--------
1. Testing 
   f101 integrity check
   check test results / full circle tests
   top-30 bank test
   
2. Final uses 
   final uses of data: typical charts/forms/text comment
      projection model / forecast (in Pandas)
   top 5 bank balance output 
   <ccorp> output
   
3. Previous versions audit
   audit previous versions of cbr_db
   audit previous php/python implementations, html, database keys
   
4. Other
   run locally on linux

Optional
--------
instead on myslimport can run LOAD DATA INFILE '/full/path/to/temp.txt' - with mysqlconnector, no using mysqlimport necessary
more documentation to readme.md and  folder 'doc'
add --alldates key in commandline interface 
read from DBF to final database directly
sql outputs to screen
   -v for verbose
   date formats
timer
sqla abstraction/sql optimisation
show all available dates in directory

RISKS
=====
Encountered before:
   CSV written to file not complete (fewer lines than other)
   f101 has residuals not 0
   
What license? 

COMMENT
=======
bottle framework to put to localhost/web 
something to start mysql server/daemon (now manually in Windows)
SQLA abstraction of SQL queries
‘Import tables’ is not very clean, it is actually about importing names/plan from files
join files conn.py and download?

DONE
====
Before 2015-06-15 05:20 PM
.gitignore - delete it
supply Excel file output, specification and previous realisation for –csv –xls keys. 

2015-06-15 05:20 PM
build xls file 
make output common directory - write .sql there
delete temp sql files in ouptput directory 
new dates interface

2015-06-16 05:24 PM
read private data to final/raw database 
    Private data is text files with same logic structure as DBF. A separate altorightm is
	used to convert these text files to csv's readable by mysqlimport. These CSVs can be 
	imported directly to raw database. text files are in data.private.rar, conversion algorithm is in veb_txt.py.
	
	Steps:
    define directories where private data text files are stored, and csv files are created
    convert text files to csv files (using veb_txt.py). 
	import csv files to raw database (import_veb.bat). import_veb.bat imports all available csv files, because it is a quick job to do. I think myslqimport call is slightly different from the one used for other csv files - please document it too.
	integrate calls into bankform.py command line interface (no dates, this will for now work on all files):
	     bankform.py make csv <FORM> --private-data [--all-dates]
         bankform.py import csv <FORM> --private-data [--all-dates]

2015-06-17 11:22 AM
update tests for cli_dates.py - see commented code in bootom of file cli_dates.py (I changed the command line interface, now several date formats can be supplied as input)
EP: made additional comments/doctrings, done

inspect date_engine.py for orphan functions, document necessary changes. what modules use functions from there?
EP: made additional comments/doctrings + code blocks, done

2015-06-17 05:44 PM
update command: bankform.py update <FORM> 
make readme.md

2015-06-18 4:30 AM
there are warnings in mysqlimport of standard csv files, need to find out reason for these warnings (replicate same import with sql's "load data" then "show warnings")
  EP: are warnings format conversion? 
  Done(L): /r/n

2015-06-18 10:15 AM
save7z.bat - makes archive of the folder except data and output 
delete 'csv_to_excel' folder in root in repository as it was moved to issues

2015-06-22
update readme.md
create folder py3/utils and move following files there (intent - keep command files to run scripts and script files separately)
17.06.2015  00:44               175 ini.bat
17.06.2015  00:44               740 ini.py
17.06.2015  10:55                33 start_unit_tests.bat
17.06.2015  00:44               492 test-one-date.bat
17.06.2015  00:44             1 631 test-one-date.py

(not checked ) 'used in ...' docstrings in database.py not very meaningful, may go over them. better add what the function does (very concisely), not whwere it is used. can omit docstring where behavoir is self-evident.
